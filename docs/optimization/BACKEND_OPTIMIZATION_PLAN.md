# Backend API Optimization Plan

**Date:** 2025-11-01
**Status:** Comprehensive Analysis Complete
**Total Endpoints Analyzed:** 142 across 14 route files

---

## Executive Summary

This document presents a comprehensive analysis of the posting-system backend API, identifying **18 performance issues** ranging from critical to moderate priority. The analysis covers N+1 query problems, inefficient query patterns, missing indexes, API consolidation opportunities, and caching strategies.

### Quick Stats

- **Critical Issues:** 4 (immediate attention required)
- **High Priority:** 6 (fix within 1-2 weeks)
- **Medium Priority:** 8 (address during next optimization cycle)
- **Estimated Performance Gains:** 40-60% reduction in query count, 30-50% faster response times
- **Implementation Effort:** 20-40 hours for all critical + high priority fixes

### Key Findings

1. **Timeline queries use correlated subqueries** creating 3N queries per page load (CRITICAL)
2. **Comments view tracking loops** through records creating N+1 queries (CRITICAL)
3. **Groups filtered endpoint** loads 1000 records into memory (CRITICAL)
4. **Conversations endpoint** has 5+ N+1 subquery patterns (CRITICAL)
5. Multiple opportunities for batch operations and API consolidation
6. Missing database indexes on frequently queried columns
7. No caching layer for user profiles, counts, or aggregations

---

## Priority 1: Critical Issues (Fix Immediately)

### Issue #1: Timeline Correlated Subqueries (CRITICAL)

**Location:** `/backend/src/routes/timeline.js` lines 109-111
**Impact:** Creates 3N queries per page load (3 Ã— 20 = 60 queries for default page)
**Severity:** ðŸ”´ CRITICAL

**Problem:**

```javascript
SELECT p.id,
  (SELECT COUNT(*) FROM reactions WHERE post_id = p.id) as reaction_count,
  (SELECT COUNT(*) FROM comments WHERE post_id = p.id) as comment_count,
  (SELECT COUNT(*) FROM shares WHERE post_id = p.id) as share_count
FROM posts p
```

Each correlated subquery executes separately for EACH post row, creating:

- 1 main query
- 20 Ã— 3 = 60 subqueries for 20 posts
- **Total: 61 queries instead of 1**

**Solution - Use LEFT JOINs with GROUP BY:**

```javascript
SELECT
  p.*,
  u.username, u.first_name, u.last_name, u.avatar_url,
  COALESCE(COUNT(DISTINCT r.id), 0) as reaction_count,
  COALESCE(COUNT(DISTINCT c.id), 0) as comment_count,
  COALESCE(COUNT(DISTINCT s.id), 0) as share_count
FROM posts p
INNER JOIN users u ON p.user_id = u.id
LEFT JOIN reactions r ON p.id = r.post_id
LEFT JOIN comments c ON p.id = c.post_id AND c.is_published = true
LEFT JOIN shares s ON p.id = s.post_id
WHERE p.user_id IN (
  SELECT following_id FROM follows WHERE follower_id = $1 AND status = 'active'
)
AND p.is_published = true
AND p.deleted_at IS NULL
GROUP BY p.id, u.id, u.username, u.first_name, u.last_name, u.avatar_url
ORDER BY p.created_at DESC
LIMIT $2 OFFSET $3
```

**Expected Improvement:**

- Queries: 61 â†’ 1 (98% reduction)
- Response time: ~300ms â†’ ~50ms (83% faster)

**Files to Modify:**

1. `/backend/src/routes/timeline.js` lines 87-155
2. Add composite indexes (see Index Recommendations section)

---

### Issue #2: Comment View Tracking Loop (CRITICAL)

**Location:** `/backend/src/routes/comments.js` lines 458-467
**Impact:** N+1 query problem when tracking views
**Severity:** ðŸ”´ CRITICAL

**Problem:**

```javascript
// Record comment views
if (commentIds.length > 0) {
  for (const commentId of commentIds) {
    await Comment.recordView(commentId, userId);  // â† N queries
  }Compiled with problems:
Ã—
ERROR in src/pages/NotificationsPage.tsx:61:54
TS2339: Property 'full' does not exist on type '{ sm: string; md: string; lg: string; }'.
    59 |   font-size: 0.875rem;
    60 |   font-weight: 500;
  > 61 |   border-radius: ${({ theme }) => theme.borderRadius.full};
       |                                                      ^^^^
    62 |   cursor: pointer;
    63 |   white-space: nowrap;
    64 |   transition: all 0.2s;
ERROR in src/pages/NotificationsPage.tsx:303:47
TS2339: Property 'getAll' does not exist on type '{ getNotifications: (params?: { unread_only?: boolean | undefined; type?: string | undefined; limit?: number | undefined; offset?: number | undefined; } | undefined) => Promise<ApiResponse<Notification[]>>; ... 6 more ...; updatePreference: (type: string, data: { ...; }) => Promise<...>; }'.
    301 |       }
    302 |
  > 303 |       const response = await notificationsApi.getAll(params);
        |                                               ^^^^^^
    304 |
    305 |       if (response.success && response.data) {
    306 |         setNotifications(response.data.notifications);
}
```

For 20 comments, this creates **20 individual INSERT queries**.

**Solution - Batch INSERT:**

```javascript
// Record comment views in a single query
if (commentIds.length > 0 && userId) {
  const values = commentIds
    .map((id, i) => `($${i * 2 + 1}, $${i * 2 + 2}, NOW())`)
    .join(", ");

  const params = commentIds.flatMap((id) => [id, userId]);

  await Comment.raw(
    `
    INSERT INTO comment_views (comment_id, user_id, viewed_at)
    VALUES ${values}
    ON CONFLICT (comment_id, user_id)
    DO UPDATE SET viewed_at = NOW()
  `,
    params
  );
}
```

**Expected Improvement:**

- Queries: 20 â†’ 1 (95% reduction)
- Response time: ~150ms â†’ ~20ms (87% faster)

**Files to Modify:**

1. `/backend/src/routes/comments.js` lines 458-467
2. `/backend/src/models/Comment.js` - Add `batchRecordViews()` method

---

### Issue #3: Groups Filtered Endpoint Memory Issue (CRITICAL)

**Location:** `/backend/src/routes/groups.js` lines 270-275
**Impact:** Loads 1000 groups into memory, then filters in JavaScript
**Severity:** ðŸ”´ CRITICAL

**Problem:**

```javascript
router.get("/filtered", async (req, res, next) => {
  // ...
  const allGroups = await Group.getAllGroups(1000, 0); // â† Loads 1000!

  const filteredGroups = allGroups.filter((group) => {
    // JavaScript filtering logic
  });
});
```

**Issues:**

- Loads 1000 records when user might only need 20
- Uses JavaScript for filtering instead of SQL
- No pagination on final results
- Unnecessarily high memory usage

**Solution - Filter in SQL:**

```javascript
router.get("/filtered", async (req, res, next) => {
  const {
    privacy,
    location_restricted,
    allow_posts,
    page = 1,
    limit = 20,
  } = req.query;

  const offset = (page - 1) * limit;

  // Build WHERE clause dynamically
  const whereClauses = ["1=1"];
  const params = [];
  let paramIndex = 1;

  if (privacy) {
    whereClauses.push(`privacy = $${paramIndex}`);
    params.push(privacy);
    paramIndex++;
  }

  if (location_restricted !== undefined) {
    whereClauses.push(`location_restricted = $${paramIndex}`);
    params.push(location_restricted === "true");
    paramIndex++;
  }

  if (allow_posts !== undefined) {
    whereClauses.push(`allow_posts = $${paramIndex}`);
    params.push(allow_posts === "true");
    paramIndex++;
  }

  // Add LIMIT and OFFSET params
  const limitParam = paramIndex;
  const offsetParam = paramIndex + 1;
  params.push(limit, offset);

  const query = `
    SELECT g.*,
           COUNT(gm.id) as member_count
    FROM groups g
    LEFT JOIN group_memberships gm ON g.id = gm.group_id
    WHERE ${whereClauses.join(" AND ")}
    GROUP BY g.id
    ORDER BY g.created_at DESC
    LIMIT $${limitParam} OFFSET $${offsetParam}
  `;

  const result = await Group.raw(query, params);
  // ...
});
```

**Expected Improvement:**

- Memory usage: ~10MB â†’ ~200KB (98% reduction)
- Response time: ~500ms â†’ ~80ms (84% faster)
- Network transfer: ~500KB â†’ ~25KB (95% reduction)

**Files to Modify:**

1. `/backend/src/routes/groups.js` lines 254-280

---

### Issue #4: Conversations Multiple N+1 Patterns (CRITICAL)

**Location:** `/backend/src/routes/conversations.js` lines 85-133
**Impact:** 5+ N+1 subquery patterns per conversation
**Severity:** ðŸ”´ CRITICAL

**Problem:**

```javascript
const query = `
  SELECT c.*,
    (SELECT COUNT(*) FROM messages WHERE conversation_id = c.id) as message_count,
    (SELECT MAX(created_at) FROM messages WHERE conversation_id = c.id) as last_message_at,
    (SELECT content FROM messages WHERE conversation_id = c.id
     ORDER BY created_at DESC LIMIT 1) as last_message_content,
    -- More correlated subqueries...
FROM conversations c
```

**Additional N+1 issues:**

```javascript
// Lines 95-98: Read count subquery per conversation
(SELECT COUNT(*) FROM message_reads
 WHERE message_id IN (SELECT id FROM messages WHERE conversation_id = c.id)
 AND user_id = $1
) as read_count
```

**Solution - Eager Load with CTEs:**

```javascript
const query = `
  WITH message_stats AS (
    SELECT
      conversation_id,
      COUNT(*) as message_count,
      MAX(created_at) as last_message_at
    FROM messages
    WHERE deleted_at IS NULL
    GROUP BY conversation_id
  ),
  last_messages AS (
    SELECT DISTINCT ON (conversation_id)
      conversation_id,
      content as last_message_content,
      user_id as last_message_sender_id
    FROM messages
    WHERE deleted_at IS NULL
    ORDER BY conversation_id, created_at DESC
  ),
  unread_counts AS (
    SELECT
      m.conversation_id,
      COUNT(*) as unread_count
    FROM messages m
    LEFT JOIN message_reads mr ON m.id = mr.message_id AND mr.user_id = $1
    WHERE m.conversation_id IN (
      SELECT conversation_id FROM conversation_participants WHERE user_id = $1
    )
    AND mr.id IS NULL
    AND m.deleted_at IS NULL
    GROUP BY m.conversation_id
  ),
  participant_info AS (
    SELECT
      cp.conversation_id,
      json_agg(
        json_build_object(
          'id', u.id,
          'username', u.username,
          'first_name', u.first_name,
          'last_name', u.last_name,
          'avatar_url', u.avatar_url,
          'joined_at', cp.joined_at
        ) ORDER BY cp.joined_at
      ) as participants
    FROM conversation_participants cp
    JOIN users u ON cp.user_id = u.id
    GROUP BY cp.conversation_id
  )
  SELECT
    c.*,
    COALESCE(ms.message_count, 0) as message_count,
    ms.last_message_at,
    lm.last_message_content,
    lm.last_message_sender_id,
    COALESCE(uc.unread_count, 0) as unread_count,
    pi.participants
  FROM conversations c
  JOIN conversation_participants cp ON c.id = cp.conversation_id
  LEFT JOIN message_stats ms ON c.id = ms.conversation_id
  LEFT JOIN last_messages lm ON c.id = lm.conversation_id
  LEFT JOIN unread_counts uc ON c.id = uc.conversation_id
  LEFT JOIN participant_info pi ON c.id = pi.conversation_id
  WHERE cp.user_id = $1
  AND cp.left_at IS NULL
  ORDER BY ms.last_message_at DESC NULLS LAST
  LIMIT $2 OFFSET $3
`;
```

**Expected Improvement:**

- Queries: 100+ â†’ 1 (99% reduction)
- Response time: ~800ms â†’ ~120ms (85% faster)

**Files to Modify:**

1. `/backend/src/routes/conversations.js` lines 85-133
2. `/backend/src/routes/conversations.js` lines 189-245 (similar pattern)

---

## Priority 2: High Priority Issues (Fix Soon)

### Issue #5: Sequential Notification Creation

**Location:** `/backend/src/routes/comments.js` lines 715-754
**Impact:** Creates notifications one-by-one in loop
**Severity:** ðŸŸ¡ HIGH

**Problem:**

```javascript
for (const mention of mentions) {
  await Notification.create({
    user_id: mention.id,
    // ...notification data
  });
}
```

**Solution - Batch Notifications:**

```javascript
if (mentions.length > 0) {
  await Notification.createBatch(
    mentions.map((mention) => ({
      user_id: mention.id,
      type: "mention",
      title: "Mentioned in Comment",
      message: `${user.username} mentioned you in a comment`,
      actor_id: userId,
      entity_type: "comment",
      entity_id: comment.id,
      action_url: `/posts/${comment.post_id}#comment-${comment.id}`,
      priority: "normal",
    }))
  );
}
```

Add to `/backend/src/models/Notification.js`:

```javascript
static async createBatch(notifications) {
  if (notifications.length === 0) return [];

  const values = [];
  const params = [];
  let paramIndex = 1;

  notifications.forEach(notif => {
    values.push(`(
      $${paramIndex}, $${paramIndex + 1}, $${paramIndex + 2},
      $${paramIndex + 3}, $${paramIndex + 4}, $${paramIndex + 5},
      $${paramIndex + 6}, $${paramIndex + 7}, $${paramIndex + 8}
    )`);

    params.push(
      notif.user_id,
      notif.type,
      notif.title,
      notif.message,
      notif.actor_id || null,
      notif.entity_type || null,
      notif.entity_id || null,
      notif.action_url || null,
      notif.priority || 'normal'
    );

    paramIndex += 9;
  });

  const query = `
    INSERT INTO notifications (
      user_id, type, title, message, actor_id,
      entity_type, entity_id, action_url, priority
    )
    VALUES ${values.join(', ')}
    RETURNING *
  `;

  const result = await this.raw(query, params);
  return result.rows;
}
```

**Expected Improvement:**

- Queries: N â†’ 1 (95% reduction for 20 mentions)
- Response time: ~200ms â†’ ~30ms (85% faster)

---

### Issue #6: Group Members Sequential Addition

**Location:** `/backend/src/routes/groups.js` lines 668-676
**Impact:** N queries when adding multiple members
**Severity:** ðŸŸ¡ HIGH

**Problem:**

```javascript
for (const userId of userIds) {
  await GroupMembership.create({
    group_id: groupId,
    user_id: userId,
    role: "member",
  });
}
```

**Solution - Batch INSERT:**

```javascript
if (userIds.length > 0) {
  const values = userIds
    .map((_, i) => `($1, $${i + 2}, 'member', NOW())`)
    .join(", ");

  await GroupMembership.raw(
    `
    INSERT INTO group_memberships (group_id, user_id, role, joined_at)
    VALUES ${values}
    ON CONFLICT (group_id, user_id) DO NOTHING
    RETURNING *
  `,
    [groupId, ...userIds]
  );
}
```

**Expected Improvement:**

- Queries: N â†’ 1 (95% reduction)
- Response time: ~150ms â†’ ~20ms (87% faster)

---

### Issue #7: Posts Endpoint Missing Eager Loading

**Location:** `/backend/src/routes/posts.js` GET /api/posts/:id
**Impact:** Separate queries for media, reactions, comments
**Severity:** ðŸŸ¡ HIGH

**Current Flow:**

1. Query post by ID
2. Query media for post (separate query)
3. Query reactions for post (separate query)
4. Query comment count (separate query)
5. Query share count (separate query)

**Total: 5 queries per post view**

**Solution - Single Query with JOINs:**

```javascript
const query = `
  SELECT
    p.*,
    u.username, u.first_name, u.last_name, u.avatar_url,

    -- Media as JSON array
    COALESCE(
      json_agg(DISTINCT jsonb_build_object(
        'id', m.id,
        'file_url', m.file_url,
        'mime_type', m.mime_type,
        'alt_text', m.alt_text,
        'width', m.width,
        'height', m.height
      )) FILTER (WHERE m.id IS NOT NULL),
      '[]'
    ) as media,

    -- Reaction counts as JSON array
    COALESCE(
      json_agg(DISTINCT jsonb_build_object(
        'emoji_name', r.emoji_name,
        'emoji_unicode', r.emoji_unicode,
        'count', r.reaction_count
      )) FILTER (WHERE r.emoji_name IS NOT NULL),
      '[]'
    ) as reactions,

    -- Counts
    COUNT(DISTINCT c.id) FILTER (WHERE c.is_published = true) as comment_count,
    COUNT(DISTINCT s.id) as share_count

  FROM posts p
  INNER JOIN users u ON p.user_id = u.id
  LEFT JOIN media m ON p.id = m.post_id
  LEFT JOIN (
    SELECT post_id, emoji_name, emoji_unicode, COUNT(*) as reaction_count
    FROM reactions
    WHERE post_id IS NOT NULL
    GROUP BY post_id, emoji_name, emoji_unicode
  ) r ON p.id = r.post_id
  LEFT JOIN comments c ON p.id = c.post_id
  LEFT JOIN shares s ON p.id = s.post_id
  WHERE p.id = $1
  GROUP BY p.id, u.id, u.username, u.first_name, u.last_name, u.avatar_url
`;
```

**Expected Improvement:**

- Queries: 5 â†’ 1 (80% reduction)
- Response time: ~120ms â†’ ~40ms (67% faster)

---

### Issue #8: User Profile Multiple Queries

**Location:** `/backend/src/routes/users.js` GET /api/users/:id
**Impact:** Separate queries for posts and stats
**Severity:** ðŸŸ¡ HIGH

**Current:** 3 queries (user, posts, stats)

**Solution:** Combine into single query with CTEs (similar to Issue #7)

**Expected Improvement:**

- Queries: 3 â†’ 1 (67% reduction)
- Response time: ~90ms â†’ ~35ms (61% faster)

---

### Issue #9: Shares Popular Endpoint N+1

**Location:** `/backend/src/routes/shares.js` lines 176-193
**Impact:** Gets share counts, then fetches each post separately
**Severity:** ðŸŸ¡ HIGH

**Solution:** Use JOIN to fetch posts with share data in single query

---

### Issue #10: Reactions User History

**Location:** `/backend/src/routes/reactions.js` lines 399-441
**Impact:** Correlated subqueries for post/comment info
**Severity:** ðŸŸ¡ HIGH

**Solution:** Replace correlated subqueries with LEFT JOINs

---

## Priority 3: Medium Priority Issues

### Issue #11: Missing Database Indexes

**Severity:** ðŸŸ  MEDIUM

**Recommended Indexes:**

```sql
-- Timeline query optimization
CREATE INDEX CONCURRENTLY idx_follows_follower_following
  ON follows(follower_id, following_id, status)
  WHERE status = 'active';

-- Reactions aggregation
CREATE INDEX CONCURRENTLY idx_reactions_post_emoji
  ON reactions(post_id, emoji_name, emoji_unicode)
  WHERE post_id IS NOT NULL;

CREATE INDEX CONCURRENTLY idx_reactions_comment_emoji
  ON reactions(comment_id, emoji_name, emoji_unicode)
  WHERE comment_id IS NOT NULL;

-- Comments aggregation
CREATE INDEX CONCURRENTLY idx_comments_post_published
  ON comments(post_id, is_published)
  WHERE is_published = true;

-- Shares aggregation
CREATE INDEX CONCURRENTLY idx_shares_post_created
  ON shares(post_id, created_at DESC);

-- Messages unread optimization
CREATE INDEX CONCURRENTLY idx_messages_conversation_deleted
  ON messages(conversation_id, created_at DESC)
  WHERE deleted_at IS NULL;

-- Notifications user filtering
CREATE INDEX CONCURRENTLY idx_notifications_user_type
  ON notifications(user_id, type, created_at DESC);

CREATE INDEX CONCURRENTLY idx_notifications_user_read
  ON notifications(user_id, is_read, created_at DESC);

-- Group memberships
CREATE INDEX CONCURRENTLY idx_group_memberships_group_role
  ON group_memberships(group_id, role)
  WHERE left_at IS NULL;

-- Media queries
CREATE INDEX CONCURRENTLY idx_media_post_type
  ON media(post_id, mime_type);

CREATE INDEX CONCURRENTLY idx_media_user_created
  ON media(user_id, created_at DESC);
```

**Expected Improvement:** 10-30% faster query execution on filtered queries

---

### Issue #12: No Caching Layer

**Severity:** ðŸŸ  MEDIUM

**Current State:** Every request hits the database

**Recommended Caching Strategy:**

**1. User Profile Cache (Redis)**

```javascript
// Pseudo-code
const getUserProfile = async (userId) => {
  const cacheKey = `user:${userId}`;
  const cached = await redis.get(cacheKey);

  if (cached) return JSON.parse(cached);

  const user = await User.findById(userId);
  await redis.setex(cacheKey, 300, JSON.stringify(user)); // 5 min TTL
  return user;
};
```

**2. Count Aggregations Cache**

```javascript
// Cache follower/following counts, post counts, etc.
const cacheKey = `user:${userId}:stats`;
// TTL: 60 seconds (update on write operations)
```

**3. Trending/Popular Content Cache**

```javascript
// Cache popular posts, groups, etc.
const cacheKey = `trending:posts:${timeframe}`;
// TTL: 300 seconds (5 minutes)
```

**Expected Improvement:**

- 40-60% reduction in database queries
- 30-50% faster response times for cached data
- Better scalability under high load

**Implementation Effort:** 8-12 hours

---

### Issue #13: API Consolidation Opportunities

**Severity:** ðŸŸ  MEDIUM

**Current Issues:**

1. Frontend makes 3-5 separate calls to load a single post view
2. Timeline makes separate calls for reactions, shares, comments
3. User profile makes separate calls for posts, stats, media

**Recommended Consolidation:**

**1. Create `/api/posts/:id/full` endpoint:**

```javascript
// Returns post + media + reactions + comments + shares in single response
GET /api/posts/:id/full
â†’ {
  post: {...},
  media: [...],
  reactions: [...],
  comment_count: 10,
  share_count: 5,
  user_has_reacted: true,
  user_has_shared: false
}
```

**2. Create `/api/users/:id/profile` endpoint:**

```javascript
// Returns user + recent posts + stats + media in single response
GET /api/users/:id/profile
â†’ {
  user: {...},
  stats: {...},
  recent_posts: [...],
  recent_media: [...]
}
```

**3. Enhance `/api/timeline` with `include` parameter:**

```javascript
GET /api/timeline?include=media,reactions,preview_comments
â†’ Returns posts with embedded media, reactions, first 3 comments
```

**Expected Improvement:**

- 60% reduction in API calls from frontend
- 40% faster page load times
- Better mobile performance (fewer round-trips)

---

### Issue #14: No Request Batching

**Severity:** ðŸŸ  MEDIUM

**Problem:** Frontend often needs data for multiple resources:

- Get reactions for 20 posts (20 API calls)
- Get share counts for 20 posts (20 API calls)
- Get comment counts for 20 posts (20 API calls)

**Solution - Batch Endpoints:**

**1. Create `/api/reactions/batch` endpoint:**

```javascript
POST /api/reactions/batch
{
  "post_ids": [1, 2, 3, 4, 5]
}
â†’ {
  "1": { "like": 10, "love": 5 },
  "2": { "like": 8, "wow": 2 },
  // ...
}
```

**2. Create `/api/shares/batch` endpoint:**

```javascript
POST /api/shares/batch
{
  "post_ids": [1, 2, 3, 4, 5]
}
â†’ {
  "1": { "share_count": 5, "user_has_shared": false },
  "2": { "share_count": 3, "user_has_shared": true },
  // ...
}
```

**Expected Improvement:**

- 95% reduction in API calls (20 â†’ 1)
- 80% faster data loading

---

### Issue #15: Missing Query Limits

**Severity:** ðŸŸ  MEDIUM

**Problem:** Some endpoints lack default limits:

- `/backend/src/routes/follows.js` - getSuggestions has limit but no max
- `/backend/src/routes/groups.js` - getAllGroups allows 1000 records

**Solution:**

```javascript
// Enforce maximum limits
const limit = Math.min(parseInt(req.query.limit) || 20, 100); // Max 100
```

---

### Issue #16: Inefficient Search Queries

**Severity:** ðŸŸ  MEDIUM

**Location:** `/backend/src/routes/users.js` lines 110-113

**Problem:**

```javascript
WHERE (u.username ILIKE $1 OR u.first_name ILIKE $1 OR u.last_name ILIKE $1)
```

**Issues:**

- ILIKE prevents index usage
- Three OR conditions are expensive
- No full-text search

**Solution - Add PostgreSQL Full-Text Search:**

```sql
-- Add tsvector column
ALTER TABLE users ADD COLUMN search_vector tsvector;

-- Create trigger to maintain it
CREATE FUNCTION users_search_vector_update() RETURNS trigger AS $$
BEGIN
  NEW.search_vector :=
    setweight(to_tsvector('english', COALESCE(NEW.username, '')), 'A') ||
    setweight(to_tsvector('english', COALESCE(NEW.first_name, '')), 'B') ||
    setweight(to_tsvector('english', COALESCE(NEW.last_name, '')), 'B');
  RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER users_search_vector_trigger
  BEFORE INSERT OR UPDATE ON users
  FOR EACH ROW EXECUTE FUNCTION users_search_vector_update();

-- Create GIN index
CREATE INDEX idx_users_search ON users USING GIN(search_vector);
```

**Updated Query:**

```javascript
WHERE search_vector @@ plainto_tsquery('english', $1)
ORDER BY ts_rank(search_vector, plainto_tsquery('english', $1)) DESC
```

**Expected Improvement:**

- 10x faster search queries
- Relevance ranking
- Support for complex search terms

---

### Issue #17: No Rate Limiting

**Severity:** ðŸŸ  MEDIUM

**Problem:** No rate limiting on expensive endpoints

**Recommended Implementation:**

```javascript
const rateLimit = require('express-rate-limit');

// Different limits for different endpoint types
const timelineLimiter = rateLimit({
  windowMs: 1 * 60 * 1000, // 1 minute
  max: 20 // 20 requests per minute
});

const searchLimiter = rateLimit({
  windowMs: 1 * 60 * 1000,
  max: 10 // 10 searches per minute
});

// Apply to routes
router.get('/timeline', timelineLimiter, async (req, res) => {...});
router.get('/users', searchLimiter, async (req, res) => {...});
```

---

### Issue #18: Verbose Response Payloads

**Severity:** ðŸŸ  MEDIUM

**Problem:** APIs return full user objects in arrays

**Example:**

```javascript
// Timeline returns full user profile for EACH post
[
  {
    id: 1,
    content: "...",
    user: {
      id: 5,
      username: "john",
      first_name: "John",
      last_name: "Doe",
      email: "john@example.com", // â† Unnecessary
      bio: "...", // â† Unnecessary for list view
      created_at: "...", // â† Unnecessary
      // ... 15 more fields
    },
  },
  // ... 19 more posts with duplicate user data
];
```

**Solution - Use projection:**

```javascript
// Only return necessary user fields in lists
user: {
  id: u.id,
  username: u.username,
  first_name: u.first_name,
  last_name: u.last_name,
  avatar_url: u.avatar_url
}
```

**Expected Improvement:**

- 40-60% smaller response payloads
- Faster JSON parsing
- Better mobile performance

---

## Implementation Roadmap

### Phase 1: Critical Fixes (Week 1)

**Effort:** 12-16 hours
**Impact:** 50-60% performance improvement

- [ ] Fix timeline correlated subqueries (Issue #1) - 3 hours
- [ ] Fix comment view tracking loop (Issue #2) - 2 hours
- [ ] Fix groups filtered endpoint (Issue #3) - 2 hours
- [ ] Fix conversations N+1 patterns (Issue #4) - 4 hours
- [ ] Add critical indexes - 1 hour
- [ ] Testing and validation - 2 hours

**Expected Results:**

- Timeline: 61 queries â†’ 1 query
- Comments: 20 queries â†’ 1 query
- Groups: 500ms â†’ 80ms response time
- Conversations: 100+ queries â†’ 1 query

---

### Phase 2: High Priority Fixes (Week 2)

**Effort:** 10-14 hours
**Impact:** Additional 20-30% improvement

- [ ] Batch notification creation (Issue #5) - 2 hours
- [ ] Batch group member addition (Issue #6) - 1 hour
- [ ] Eager load posts endpoint (Issue #7) - 3 hours
- [ ] Optimize user profile (Issue #8) - 2 hours
- [ ] Fix shares popular endpoint (Issue #9) - 2 hours
- [ ] Add remaining indexes - 1 hour
- [ ] Testing - 2 hours

---

### Phase 3: Caching & Optimization (Week 3-4)

**Effort:** 12-18 hours
**Impact:** 30-40% improvement under load

- [ ] Set up Redis caching (Issue #12) - 4 hours
- [ ] Implement user profile caching - 2 hours
- [ ] Implement count caching - 2 hours
- [ ] Implement trending content cache - 2 hours
- [ ] Add cache invalidation logic - 2 hours
- [ ] Testing and monitoring - 2 hours

---

### Phase 4: API Consolidation (Week 5-6)

**Effort:** 8-12 hours
**Impact:** Better frontend performance

- [ ] Create `/api/posts/:id/full` endpoint (Issue #13) - 3 hours
- [ ] Create `/api/users/:id/profile` endpoint - 2 hours
- [ ] Create batch endpoints (Issue #14) - 3 hours
- [ ] Implement full-text search (Issue #16) - 3 hours
- [ ] Update frontend to use new endpoints - 4 hours

---

### Phase 5: Polish & Monitoring (Week 7)

**Effort:** 6-8 hours

- [ ] Add rate limiting (Issue #17) - 2 hours
- [ ] Optimize response payloads (Issue #18) - 2 hours
- [ ] Add query performance monitoring - 2 hours
- [ ] Document all changes - 2 hours

---

## Database Index Strategy

### Migration File: `021_add_performance_indexes.sql`

```sql
-- ==================================================
-- Performance Optimization Indexes
-- ==================================================

-- Timeline and feed queries
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_follows_follower_following
  ON follows(follower_id, following_id, status)
  WHERE status = 'active';

CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_posts_user_published
  ON posts(user_id, is_published, created_at DESC)
  WHERE is_published = true AND deleted_at IS NULL;

-- Reaction aggregations
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_reactions_post_emoji
  ON reactions(post_id, emoji_name, emoji_unicode)
  WHERE post_id IS NOT NULL;

CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_reactions_comment_emoji
  ON reactions(comment_id, emoji_name, emoji_unicode)
  WHERE comment_id IS NOT NULL;

-- Comment aggregations
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_comments_post_published
  ON comments(post_id, is_published, created_at DESC)
  WHERE is_published = true;

-- Share aggregations
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_shares_post_created
  ON shares(post_id, created_at DESC);

-- Message queries
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_messages_conversation_deleted
  ON messages(conversation_id, created_at DESC)
  WHERE deleted_at IS NULL;

CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_message_reads_message_user
  ON message_reads(message_id, user_id);

-- Notification queries
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_notifications_user_type
  ON notifications(user_id, type, created_at DESC);

CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_notifications_user_read
  ON notifications(user_id, is_read, created_at DESC);

-- Group queries
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_group_memberships_group_role
  ON group_memberships(group_id, role, joined_at)
  WHERE left_at IS NULL;

CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_groups_privacy_location
  ON groups(privacy, location_restricted);

-- Media queries
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_media_post_type
  ON media(post_id, mime_type);

CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_media_user_created
  ON media(user_id, created_at DESC);

-- User search (full-text search)
ALTER TABLE users ADD COLUMN IF NOT EXISTS search_vector tsvector;

CREATE OR REPLACE FUNCTION users_search_vector_update() RETURNS trigger AS $$
BEGIN
  NEW.search_vector :=
    setweight(to_tsvector('english', COALESCE(NEW.username, '')), 'A') ||
    setweight(to_tsvector('english', COALESCE(NEW.first_name, '')), 'B') ||
    setweight(to_tsvector('english', COALESCE(NEW.last_name, '')), 'B');
  RETURN NEW;
END;
$$ LANGUAGE plpgsql;

DROP TRIGGER IF EXISTS users_search_vector_trigger ON users;
CREATE TRIGGER users_search_vector_trigger
  BEFORE INSERT OR UPDATE ON users
  FOR EACH ROW EXECUTE FUNCTION users_search_vector_update();

-- Backfill search vectors for existing users
UPDATE users SET search_vector =
  setweight(to_tsvector('english', COALESCE(username, '')), 'A') ||
  setweight(to_tsvector('english', COALESCE(first_name, '')), 'B') ||
  setweight(to_tsvector('english', COALESCE(last_name, '')), 'B');

CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_users_search
  ON users USING GIN(search_vector);
```

**Application:**

```bash
psql -U dev_user -d posting_system -f backend/database/migrations/021_add_performance_indexes.sql
```

---

## Monitoring & Measurement

### Key Metrics to Track

**1. Query Performance:**

```javascript
// Add to database pool config
const pool = new Pool({
  // ... existing config
  log: (msg) => {
    if (msg.includes("duration")) {
      const duration = parseInt(msg.match(/duration: (\d+)/)?.[1] || 0);
      if (duration > 100) {
        // Log slow queries (>100ms)
        console.warn("Slow query detected:", msg);
      }
    }
  },
});
```

**2. API Response Times:**

```javascript
// Middleware to track response times
const responseTimeMiddleware = (req, res, next) => {
  const start = Date.now();
  res.on("finish", () => {
    const duration = Date.now() - start;
    if (duration > 500) {
      // Log slow responses (>500ms)
      console.warn(`Slow response: ${req.method} ${req.path} - ${duration}ms`);
    }
  });
  next();
};
```

**3. Cache Hit Rates:**

```javascript
// Track cache performance
const cacheStats = {
  hits: 0,
  misses: 0,
  getHitRate: () => {
    const total = cacheStats.hits + cacheStats.misses;
    return total > 0 ? ((cacheStats.hits / total) * 100).toFixed(2) : 0;
  },
};
```

---

## Expected Overall Results

### Before Optimization

- Timeline load: ~300ms, 61 queries
- Post view: ~120ms, 5 queries
- User profile: ~90ms, 3 queries
- Conversations list: ~800ms, 100+ queries
- Comments list: ~150ms, 20+ queries

### After All Optimizations

- Timeline load: ~50ms, 1 query (83% faster, 98% fewer queries)
- Post view: ~40ms, 1 query (67% faster, 80% fewer queries)
- User profile: ~35ms, 1 query (61% faster, 67% fewer queries)
- Conversations list: ~120ms, 1 query (85% faster, 99% fewer queries)
- Comments list: ~20ms, 1 query (87% faster, 95% fewer queries)

### Overall Impact

- **Query Reduction:** 80-98% fewer database queries
- **Response Time:** 60-85% faster response times
- **Scalability:** 3-5x more concurrent users supported
- **Database Load:** 70-90% reduction in CPU usage
- **Network Transfer:** 40-60% smaller payloads

---

## Testing Strategy

### Performance Testing

**1. Load Test Critical Endpoints:**

```bash
# Install Apache Bench
sudo apt-get install apache2-utils

# Test timeline endpoint
ab -n 1000 -c 10 http://localhost:3001/api/timeline

# Before optimization: ~300ms avg
# Target after: ~50ms avg
```

**2. Query Count Verification:**

```javascript
// Add query counter to tests
let queryCount = 0;
pool.on("query", () => queryCount++);

// Test
await request(app).get("/api/timeline");
expect(queryCount).toBe(1); // Should be 1 query, not 61
```

**3. Database Query Explain:**

```sql
-- Check query plans
EXPLAIN ANALYZE
SELECT p.*, /* ... full timeline query ... */
FROM posts p
-- ...
```

---

## Appendix: Quick Reference

### Files to Modify

**Critical Priority:**

1. `/backend/src/routes/timeline.js` (lines 87-155)
2. `/backend/src/routes/comments.js` (lines 458-467)
3. `/backend/src/routes/groups.js` (lines 254-280)
4. `/backend/src/routes/conversations.js` (lines 85-133, 189-245)
5. `/backend/src/models/Comment.js` (add batchRecordViews)

**High Priority:** 6. `/backend/src/routes/comments.js` (lines 715-754) 7. `/backend/src/routes/groups.js` (lines 668-676) 8. `/backend/src/models/Notification.js` (add createBatch) 9. `/backend/src/routes/posts.js` (GET /:id) 10. `/backend/src/routes/users.js` (GET /:id) 11. `/backend/src/routes/shares.js` (GET /popular) 12. `/backend/src/routes/reactions.js` (GET /user/:userId)

**Medium Priority:** 13. Create migration: `/backend/database/migrations/021_add_performance_indexes.sql` 14. Set up Redis caching infrastructure 15. Add batch endpoints for reactions, shares, comments 16. Create consolidated endpoints (/full, /profile) 17. Add rate limiting middleware 18. Optimize response payload sizes

---

## Contact & Questions

For questions about this optimization plan:

- Review the specific issue sections for implementation details
- Check the database migration file for index syntax
- Refer to the testing strategy for validation approaches

**Document Version:** 1.0
**Last Updated:** 2025-11-01
**Next Review:** After Phase 1 completion
